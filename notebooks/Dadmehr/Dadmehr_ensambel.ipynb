{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define epochs for all models.\n",
    "epochs = 10\n",
    "\n",
    "train = pd.read_csv('sign_mnist_train.csv')\n",
    "test = pd.read_csv('sign_mnist_test.csv')\n",
    "\n",
    "#Datasets as numpy arrays\n",
    "train_data = np.array(train, dtype = 'float32')\n",
    "test_data = np.array(test, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class labels for easy interpretation\n",
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
    "               'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for the image is:  R\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sanity check - plot a few images and labels\n",
    "i = random.randint(1,train.shape[0])\n",
    "fig1, ax1 = plt.subplots(figsize=(2,2))\n",
    "plt.imshow(train_data[i,1:].reshape((28,28))) \n",
    "print(\"Label for the image is: \", class_names[int(train_data[i,0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for the image is:  Q\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sanity check - plot a few images and labels\n",
    "i = random.randint(1,train.shape[0])\n",
    "fig1, ax1 = plt.subplots(figsize=(2,2))\n",
    "plt.imshow(train_data[i,1:].reshape((28,28))) \n",
    "print(\"Label for the image is: \", class_names[int(train_data[i,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data distribution visualization\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "ax1 = fig.add_subplot(221)\n",
    "train['label'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize / scale X values\n",
    "X_train = train_data[:, 1:] /255.\n",
    "X_test = test_data[:, 1:] /255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[:, 0]\n",
    "y_train_cat = to_categorical(y_train, num_classes=25)\n",
    "\n",
    "y_test = test_data[:,0]\n",
    "y_test_cat = to_categorical(y_test, num_classes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape for the neural network\n",
    "X_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\n",
    "X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1\n",
    "        ) # randomly shift images vertically (fraction of total height)\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 75)       300       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 75)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                12825     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,562\n",
      "Trainable params: 264,262\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "\n",
    "#Defining the Convolutional Neural Network\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model1.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model1.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(units = 512 , activation = 'relu'))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(units = 25 , activation = 'softmax'))\n",
    "model1.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "model1.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 25) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19560/3604358145.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlearning_rate_reduction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\dadme\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 25) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(datagen.flow(X_train,y_train_cat, batch_size = 128) ,epochs = 20 , validation_data = (X_test, y_test_cat) , callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 28, 28, 256)       20992     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 28, 28, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 14, 14, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 14, 14, 128)       2654336   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 14, 14, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 7, 7, 64)          663616    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 7, 7, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 25)                25625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,366,361\n",
      "Trainable params: 3,365,465\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model2\n",
    "model2 = Sequential() \n",
    "\n",
    "model2.add(Conv2D(256 , (9,9) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((4,4) , strides = 2 , padding = 'same'))\n",
    "model2.add(Conv2D(128 , (9,9) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "#Dropout\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((4,4) , strides = 2 , padding = 'same'))\n",
    "model2.add(Conv2D(64 , (9,9) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((4,4) , strides = 2 , padding = 'same'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(25, activation='softmax'))\n",
    "\n",
    "model2.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Earlystopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "model2.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 [==============================] - 526s 2s/step - loss: 1.1528 - accuracy: 0.6617 - val_loss: 7.0592 - val_accuracy: 0.0484\n",
      "Epoch 2/20\n",
      "215/215 [==============================] - 498s 2s/step - loss: 0.1289 - accuracy: 0.9576 - val_loss: 1.2620 - val_accuracy: 0.5983\n",
      "Epoch 3/20\n",
      "215/215 [==============================] - 509s 2s/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.2631 - val_accuracy: 0.9137\n",
      "Epoch 4/20\n",
      "215/215 [==============================] - 485s 2s/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 1.0214 - val_accuracy: 0.7326\n",
      "Epoch 5/20\n",
      "215/215 [==============================] - 501s 2s/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 3.3106 - val_accuracy: 0.4414\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(datagen.flow(X_train,y_train_cat, batch_size = 128) ,epochs = 20 , validation_data = (X_test, y_test_cat) , callbacks = [Earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 25)                78425     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97,625\n",
      "Trainable params: 97,433\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model3\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(28,28,1)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(units=25, activation='softmax'))\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "model3.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "215/215 [==============================] - 17s 77ms/step - loss: 0.9317 - accuracy: 0.7175 - val_loss: 3.2338 - val_accuracy: 0.0485 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 17s 80ms/step - loss: 0.2331 - accuracy: 0.9272 - val_loss: 1.3265 - val_accuracy: 0.6262 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 17s 79ms/step - loss: 0.1261 - accuracy: 0.9612 - val_loss: 0.2037 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 17s 80ms/step - loss: 0.0884 - accuracy: 0.9721 - val_loss: 0.0614 - val_accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 18s 82ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.0613 - val_accuracy: 0.9805 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 17s 80ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.0223 - val_accuracy: 0.9954 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 20s 91ms/step - loss: 0.0497 - accuracy: 0.9842 - val_loss: 0.0401 - val_accuracy: 0.9852 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9878\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "215/215 [==============================] - 18s 84ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.1553 - val_accuracy: 0.9497 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "215/215 [==============================] - 18s 81ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0115 - val_accuracy: 0.9972 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "215/215 [==============================] - 17s 80ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 0.0079 - val_accuracy: 0.9980 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(datagen.flow(X_train,y_train_cat, batch_size = 128) ,epochs = 10 , validation_data = (X_test, y_test_cat) , callbacks = [learning_rate_reduction], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model1 = load_model('model1.hdf5')\n",
    "model2 = load_model('model2.hdf5')\n",
    "model3 = load_model('model3.hdf5')\n",
    "models = [model1, model2, model3]\n",
    "\n",
    "preds = [model.predict(X_test) for model in models]\n",
    "preds=np.array(preds)\n",
    "summed = np.sum(preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17072/4275358702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclasses_3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0maccuracy1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0maccuracy2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0maccuracy3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "# argmax across classes\n",
    "ensemble_prediction = np.argmax(summed, axis=1)\n",
    "\n",
    "prediction1 = model1.predict(X_test) \n",
    "classes_1=np.argmax(prediction1,axis=1)\n",
    "prediction2 = model3.predict(X_test) \n",
    "classes_2=np.argmax(prediction2,axis=1)\n",
    "prediction3 = model3.predict(X_test) \n",
    "classes_3=np.argmax(prediction3,axis=1)\n",
    "\n",
    "accuracy1 = accuracy_score(y_test, prediction1)\n",
    "accuracy2 = accuracy_score(y_test, prediction2)\n",
    "accuracy3 = accuracy_score(y_test, prediction3)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_prediction)\n",
    "\n",
    "print('Accuracy Score for model1 = ', accuracy1)\n",
    "print('Accuracy Score for model2 = ', accuracy2)\n",
    "print('Accuracy Score for model3 = ', accuracy3)\n",
    "print('Accuracy Score for average ensemble = ', ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbe11984b4976a359ab278f9ccc43ec6b95599e51371f648ad9a3804396bb933"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
